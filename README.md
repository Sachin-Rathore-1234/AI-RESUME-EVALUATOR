ğŸ§  AI Resume Shortlisting & Interview Assistant System
ğŸ“Œ Overview

This project implements an AI-powered resume screening and evaluation system that goes beyond keyword matching.
It uses Large Language Models (LLMs) to simulate human recruiter judgment across multiple stages of candidate evaluation.

The system evaluates candidates on:

Semantic Role Fit (Screening)

Achievement / Impact

Ownership / Responsibility

Holistic Hiring Decision (Tiering)

The goal is to produce explainable, nuanced, and realistic hiring decisions rather than binary accept/reject outcomes.

ğŸ¯ Key Features

âœ… LLM-based Screening (JD â†” Resume semantic fit)

âœ… LLM-based Achievement Evaluation

âœ… LLM-based Ownership Evaluation

âœ… LLM-based Final Hiring Decision

âœ… Explainable outputs at every stage

âœ… Free & fast inference using Groq API

âœ… Modular, production-style architecture

ğŸ—ï¸ System Architecture
Resume + Job Description
        â”‚
        â–¼
LLM Screening (Semantic Fit)
        â”‚
        â–¼
LLM Achievement Evaluation
        â”‚
        â–¼
LLM Ownership Evaluation
        â”‚
        â–¼
LLM Holistic Decision Engine
        â”‚
        â–¼
Final Tier + Hiring Action + Explanation

Design principle:
Deterministic logic computes structure; LLMs handle qualitative judgment where human reasoning is required.

ğŸ” Evaluation Dimensions
1ï¸âƒ£ LLM Screening (Semantic Similarity)

Purpose:
Evaluate whether a resume is a reasonable fit for a role even if exact skills donâ€™t match.

Handled by: Groq-hosted LLaMA-3 model
Output:

{
  "score": 75,
  "reason": "Strong semantic alignment with minor gaps"
}

Why LLM?
Keyword matching fails on transferable skills (e.g., Kafka â†” Kinesis).
LLMs understand context and equivalence.

2ï¸âƒ£ LLM Achievement Scoring

Purpose:
Judge real-world impact, not just listed tasks.

Scoring rubric:

Score Range	Meaning
0â€“20	No real impact
21â€“40	Task-level work
41â€“60	Solid individual contribution
61â€“80	High-impact, system-level work
81â€“100	Exceptional, org-wide impact

Example output:

{
  "score": 70,
  "reason": "System-level impact with cross-team usage"
}
3ï¸âƒ£ LLM Ownership Scoring

Purpose:
Determine depth of responsibility.

Evaluates whether the candidate:

Designed vs assisted

Owned decisions

Led or executed independently

4ï¸âƒ£ LLM Holistic Decision Engine (Final)

Instead of hardcoded thresholds or static weights, the system uses an LLM as a final reasoning layer.

Inputs:

Similarity score + explanation

Achievement score + explanation

Ownership score + explanation

Job context

Output:

{
  "tier": "Tier B",
  "decision": "Conditional Offer",
  "reason": "Strong impact and ownership with partial role mismatch"
}

This mirrors how real hiring managers make decisions.

ğŸ·ï¸ Tiering Logic (Conceptual)
Tier	Meaning
Tier A	Fast-track candidate
Tier B	Technical interview / conditional offer
Tier C	Not suitable for this role

âš ï¸ Tiering is not numeric threshold-based â€” it is LLM-reasoned.

ğŸ¤– Why Groq + LLaMA-3?

âœ… Free API tier

âœ… Very low latency

âœ… No local GPU required

âœ… Open-weight models

âœ… Strong reasoning performance

Model used:

llama-3.1-8b-instant

The system is model-agnostic and can be swapped with other providers if needed.

ğŸ§© Tech Stack

Language: Python 3.11

LLM Provider: Groq API

Model: LLaMA-3 (8B Instant)

Architecture: Modular, LLM-as-Judge

Environment: Virtualenv / venv

â–¶ï¸ How to Run
1ï¸âƒ£ Clone the repository
git clone <repo-url>
cd ai-resume-evaluator
2ï¸âƒ£ Create & activate virtual environment
python -m venv venv
source venv/bin/activate
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
4ï¸âƒ£ Set Groq API key
export GROQ_API_KEY="your_api_key_here"
5ï¸âƒ£ Run the system
python main.py
ğŸ“¤ Sample Output
--- LLM SCREENING ---
Score: 75
Reason: Strong semantic alignment with minor gaps

--- LLM ACHIEVEMENT ---
Score: 70
Reason: High-impact system-level contributions

--- FINAL AI DECISION ---
Tier: Tier B
Decision: Conditional Offer
Reason: Strong impact and ownership with partial role mismatch
ğŸ§  Design Decisions & Justification
Why LLMs instead of rules?

Hiring decisions are qualitative

Rules fail on nuance

LLMs approximate human judgment

Why not train a model?

No labeled hiring data

LLMs provide zero-shot reasoning

Why not embeddings only?

Embeddings score similarity, not suitability

LLMs reason about context, impact, and trade-offs

ğŸš€ Future Enhancements

LLM-generated interview questions

Confidence and risk flags

Batch resume processing

UI (Streamlit / React)

Hybrid embedding + LLM optimization

âœ… Final Summary

This system demonstrates how LLMs can be integrated responsibly into hiring workflows by reasoning over structured signals, producing explainable decisions, and avoiding brittle rule-based logic.